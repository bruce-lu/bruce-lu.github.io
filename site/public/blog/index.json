[
    {
        "ref": "https://bruce-lu.github.io/blog/dev-ops-simple-powerful/",
        "title": "A very simple but powerful CI tool",
        "section": "blog",
        "date" : "2020.02.10",
        "body": " Goal  Build a very simple \u0026amp; light weight but powerful tool to do CI for a project, no CI/CD tool like Jenkins required. Make sure my client always able to see the changes on UAT server  Background  I have a very tight schedule, yes 2 days, to build a web application. I\u0026rsquo;d like to show the progress to our client as frequently as possible, like every 5-10 minutes. To save our effort, I didn\u0026rsquo;t install/configure any CI tool. Yes, the quickest way is to build a very simple but working one.  App\u0026rsquo;s Dockerfile FROM node:latest RUN echo \u0026quot;Asia/Shanghai\u0026quot; \u0026gt; /etc/timezone RUN mkdir -p /usr/src/app WORKDIR /usr/src/app EXPOSE 9090 ADD ./package.json /usr/src/app/package.json RUN npm install ADD ./web/package.json /usr/src/app/web/package.json RUN cd /usr/src/app/web/ \u0026amp;\u0026amp; npm install ADD . /usr/src/app RUN cd /usr/src/app/web/ \u0026amp;\u0026amp; npm run build CMD [ \u0026quot;node\u0026quot; \u0026quot;index.js\u0026quot;]  The tool #!/bin/bash # # ci-tool.sh // Suggest to put the script into Git project bin folder. # A simple App CI tool # Last update: 2/1/20 # @Author Bruce Lu export TZ=Asia/Shanghai WS=~/ws APP=$WS/antivirus #ACT_LOG=$WS/log/activities.log cd $APP #git_pull=$(git pull) echo \u0026quot;`date` - Pulling code..\u0026quot; if [ `git pull | tee -a | wc -l` -eq 1 ]; then # No code changes, exit.. exit 0 fi echo \u0026quot;`date` - Build and run new docker container..\u0026quot; cur_container_id=`docker ps -q` docker build -t antivirus . \u0026amp;\u0026amp; docker stop $cur_container_id \u0026amp;\u0026amp; docker rm $cur_container_id \u0026amp;\u0026amp; docker run -itd --restart unless-stopped -p 9090:9090 -e TZ=Asia/Shanghai antivirus #docker build -t antivirus . \u0026amp;\u0026amp; docker stop `docker ps -q` \u0026amp;\u0026amp; docker run -itd --rm -p 9090:9090 antivirus # On live: docker run -itd --restart always -p 9090:9090 antivirus echo \u0026quot;`date` - $?, container: `docker ps -q`\u0026quot; echo \u0026quot;`date` - Cleaning up dangling images..\u0026quot; docker rmi $(docker images -f \u0026quot;dangling=true\u0026quot; -q) echo \u0026quot;`date` - Done\u0026quot; cd - exit 0 admin@~/ws/antivirus/bin$cat build-docker.sh #!/bin/bash cd .. \u0026amp;\u0026amp; docker build -t antivirus . cd -  Make it a cron job on UAT server # Every 10 minutes */10 * * * * /path/to/ci-tool.sh \u0026gt;\u0026gt; /path/to/log 2\u0026gt;\u0026amp;1  Conclusion  I just focus on coding and commit/push the code to Github, no worries about the UAT server because it\u0026rsquo;d be automatically built and deployed.  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/aws-lambda-cloudwatch-sns-beanstalk-restart-copy/",
        "title": "AWS Lambda together with CloudWatch and SNS to restart Beanstalk app server as needed",
        "section": "blog",
        "date" : "2020.02.10",
        "body": " Goal  Restart Elastic Beanstalk app server automatically when needed In one of my IoT applications built with Elastic Beanstalk, we wanted to restart the beanstalk app server when there is no log activity occurred for a period of time. There is no such kind of built-in alarm-action feature in CloudWatch. My solution here is to demonstrate how to do this in Lambda, collaborating with other AWS services such as CloudWatch, SNS etc..  Pre-reqs  AWS account and proper permissions through IAM   Create SNS to receive log activities alarm notification  Go to AWS Web Console Services -\u0026gt; SNS -\u0026gt; Create a new SNS and email subscription  Create CloudWatch logging alarm based on log activities  Go to AWS Web Console CloudWatch -\u0026gt; Alarms -\u0026gt; Create Alarm -\u0026gt; Select Metrics -\u0026gt; Logs (my app logs) -\u0026gt; IncomingBytes -\u0026gt; Select  Metrics name: IncomingBytes LogGroupName: My app\u0026rsquo;s loggroup Statistic: Sum Period: 15 minutes Threshold type: Static Whenever IncomingBytes is\u0026hellip;: Lower than: 1 Next Select SNS topic to notify(We just created) (Note: There is no EC2/Beanstal restart action for Logs metrics, so we\u0026rsquo;d use Lambda later on) Next Give it a name and save   Create Lambda to take action when no log activity reported by CloudWatch  Create Lambda\n Go to AWS Web Console Create function Author from scratch Function name: Give it a name Runtime: Python 3.8 Permissions: Create a new role with basic Lambda permissions  Function code\n Handler: index.handler_restart_app_server index.py   import json import boto3 ebc = boto3.client('elasticbeanstalk') def handler_restart_app_server(event, context): response = ebc.restart_app_server( EnvironmentId='your-eb-env-id', EnvironmentName='your-eb-env-name' ) print(response) return { 'statusCode': 200, 'body': json.dumps(response) } def handler_request_log_100_lines(event, context): response = ebc.request_environment_info( EnvironmentName='your-env-name', #InfoType='tail'|'bundle' InfoType='tail' ) print('----\u0026gt;') print(response) print('\u0026lt;----') return { 'statusCode': 200, 'body': json.dumps(response) } def handler_describe_environment_health(event, context): response = ebc.describe_environment_health( EnvironmentId='your-env-Id', EnvironmentName='your-env-name', AttributeNames=[ 'Status', ]) #print(response) return { \u0026quot;statusCode\u0026quot;: 200, \u0026quot;body\u0026quot;: json.dumps(response) }  Add Lambda Trigger The purpose is to trigger our Lambda function whenever we got no log actitiy notification in our SNS topic\n Go to AWS Lambda function console Go to designer Add trigger: Select SNS topic we created  Testing Just watch for the notification from our topic. Every time we get notification the Elastic Beanstalk app server would be restarted\nConclusion We achived our goal to restart EB app server when no log activity reported by CloudWatch.\n What we\u0026rsquo;ve done  Created SNS topic to receive notification from CloudWatch Alarm Created Alarm in CloudWatch to monitor log metrics Created Lambda function to handle SNS notification event   "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/aws-api-gateway-lambda/",
        "title": "AWS API Gateway with Lambda Integration",
        "section": "blog",
        "date" : "2020.02.05",
        "body": " Goal  Demonstrate how to integrate AWS Lambda with API Gateway  Pre-reqs  AWS account and proper permissions through IAM   Build a Lambda function  Log on AWS Web Console Services -\u0026gt; Lambda -\u0026gt; Create function\n Function name: Lambda-API-Gateway-Demo Runtime: Node.js 12.x Permissions: Create a new role with basic Lambda permissions Click Create function button  Function code\n Code entry type: Edit code inline (other options: Upload a .zip file; Upload from S3) Runtime: Node.js 12.x Handler: index.handler index.js   exports.handler = async (event) =\u0026gt; { // TODO implement const response = { statusCode: 200, body: JSON.stringify('Hello from Lambda!'), }; return response; };  Testing  Configure test event  Create new test event Event template: Hello World Event name: LambdaDemo Keep the rest as default Click Test button to test Log output   { \u0026quot;statusCode\u0026quot;: 200, \u0026quot;body\u0026quot;: \u0026quot;\\\u0026quot;Hello from Lambda!\\\u0026quot;\u0026quot; }  START RequestId: 30020ce5-86be-47d1-ba61-ef08393f9dc7 Version: $LATEST END RequestId: 30020ce5-86be-47d1-ba61-ef08393f9dc7 REPORT RequestId: 30020ce5-86be-47d1-ba61-ef08393f9dc7\tDuration: 2.99 ms\tBilled Duration: 100 ms\tMemory Size: 128 MB\tMax Memory Used: 64 MB\tInit Duration: 423.93 ms   Add trigger  Go to Designer UI of the function Add trigger Trigger configuration: API Gateway (other options: AWS IoT, Application Load Balancer, CloudWatch Events, CloudWatch Logs, DynamoDB, Kinesis, S3, SNS, SQS) API: Create a new API Security: Open (for testing purpose, not for production) Click Add button API Gateway looks like:   Lambda-API-Gateway-Demo-API arn:aws-cn:execute-api:cn-northwest-1:005464510748:5uac1lg2va/*/*/Lambda-API-Gateway-Demo API: api-gateway/5uac1lg2va/*/*/Lambda-API-Gateway-DemoAPI endpoint: https://5uac1lg2va.execute-api.cn-northwest-1.amazonaws.com.cn/default/Lambda-API-Gateway-Demo API name: Lambda-API-Gateway-Demo-API   Validate the integration\n Open the link https://5uac1lg2va.execute-api.cn-northwest-1.amazonaws.com.cn/default/Lambda-API-Gateway-Demo on browser \u0026ldquo;Hello from Lambda!\u0026rdquo; would be displayed   Conclusion We achieved our goal successfully: AWS Lambda integration with API Gateway\n What we\u0026rsquo;ve done  Created Lambda function Created API Gateway and added it as the Trigger of Lambda function Validation   "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/aws-elastic-beanstalk-practices/",
        "title": "AWS Elastic Beanstalk practices",
        "section": "blog",
        "date" : "2019.11.14",
        "body": " Pre-reqs  aws-access-id \u0026amp; aws-secret-key are required   Log on AWS console and generate the key\n Download and install EB CLI  https://docs.amazonaws.cn/console/elasticbeanstalk/eb-cli-install\nGet started with a simple PHP application on EB  Commands would be used  mkdir zaws-eb-p-blue cd zaws-eb-p-blue/ ls -ltr eb init -p PHP # or just eb init without -p, there would be more options ls echo \u0026quot;Hello World\u0026quot; \u0026gt; index.html eb create dev-env eb open   Commands output reference  admin@~/ws/zaws-eb-p-blue$eb init -p PHP Select a default region 1) us-east-1 : US East (N. Virginia) 2) us-west-1 : US West (N. California) 3) us-west-2 : US West (Oregon) 4) eu-west-1 : EU (Ireland) 5) eu-central-1 : EU (Frankfurt) 6) ap-south-1 : Asia Pacific (Mumbai) 7) ap-southeast-1 : Asia Pacific (Singapore) 8) ap-southeast-2 : Asia Pacific (Sydney) 9) ap-northeast-1 : Asia Pacific (Tokyo) 10) ap-northeast-2 : Asia Pacific (Seoul) 11) sa-east-1 : South America (Sao Paulo) 12) cn-north-1 : China (Beijing) 13) cn-northwest-1 : China (Ningxia) 14) us-east-2 : US East (Ohio) 15) ca-central-1 : Canada (Central) 16) eu-west-2 : EU (London) 17) eu-west-3 : EU (Paris) (default is 3): 13 Application zaws-eb-p-blue has been created. admin@~/ws/aws-elastic-beanstalk-cli-setup/zaws-eb-p-blue$echo \u0026quot;Hello World\u0026quot; \u0026gt; index.html admin@~/ws/aws-elastic-beanstalk-cli-setup/zaws-eb-p-blue$ls admin@~/ws/aws-elastic-beanstalk-cli-setup/zaws-eb-p-blue$echo \u0026quot;Hello World\u0026quot; \u0026gt; index.html admin@~/ws/aws-elastic-beanstalk-cli-setup/zaws-eb-p-blue$eb create dev-env Creating application version archive \u0026quot;app-191114_102219\u0026quot;. Uploading zaws-eb-p-blue/app-191114_102219.zip to S3. This may take a while. Upload Complete. Environment details for: dev-env Application name: zaws-eb-p-blue Region: cn-northwest-1 Deployed Version: app-191114_102219 Environment ID: e-sawuybrtg2 Platform: arn:aws-cn:elasticbeanstalk:cn-northwest-1::platform/PHP 7.3 running on 64bit Amazon Linux/2.9.0 Tier: WebServer-Standard-1.0 CNAME: UNKNOWN Updated: 2019-11-14 02:22:24.384000+00:00 Printing Status: 2019-11-14 02:22:23 INFO createEnvironment is starting. 2019-11-14 02:22:24 INFO Using elasticbeanstalk-cn-northwest-1-005464510748 as Amazon S3 storage bucket for environment data. -- Events -- (safe to Ctrl+C) 2019-11-14 02:22:44 INFO Created security group named: sg-07c1f2d369b203edb 2019-11-14 02:22:44 INFO Created load balancer named: awseb-e-s-AWSEBLoa-1W1Z2T64ZALSZ 2019-11-14 02:23:00 INFO Created security group named: awseb-e-sawuybrtg2-stack-AWSEBSecurityGroup-1DGBM8AL2W9RD 2019-11-14 02:23:01 INFO Created Auto Scaling launch configuration named: awseb-e-sawuybrtg2-stack-AWSEBAutoScalingLaunchConfiguration-1DZNEYBFGYMF6 2019-11-14 02:23:48 INFO Created Auto Scaling group named: awseb-e-sawuybrtg2-stack-AWSEBAutoScalingGroup-1VYC4P71PSAT6 2019-11-14 02:23:48 INFO Waiting for EC2 instances to launch. This may take a few minutes. 2019-11-14 02:24:03 INFO Created Auto Scaling group policy named: arn:aws-cn:autoscaling:cn-northwest-1:005464510748:scalingPolicy:fd552d69-7117-42c3-a1e5-cd0686f05ccd:autoScalingGroupName/awseb-e-sawuybrtg2-stack-AWSEBAutoScalingGroup-1VYC4P71PSAT6:policyName/awseb-e-sawuybrtg2-stack-AWSEBAutoScalingScaleUpPolicy-18PVQB8L5MBPR 2019-11-14 02:24:03 INFO Created Auto Scaling group policy named: arn:aws-cn:autoscaling:cn-northwest-1:005464510748:scalingPolicy:b20a5336-7f78-44aa-9075-7b1486996610:autoScalingGroupName/awseb-e-sawuybrtg2-stack-AWSEBAutoScalingGroup-1VYC4P71PSAT6:policyName/awseb-e-sawuybrtg2-stack-AWSEBAutoScalingScaleDownPolicy-HLU17ASRWM2N 2019-11-14 02:24:03 INFO Created CloudWatch alarm named: awseb-e-sawuybrtg2-stack-AWSEBCloudwatchAlarmHigh-1JE1KAT37CRIB 2019-11-14 02:24:03 INFO Created CloudWatch alarm named: awseb-e-sawuybrtg2-stack-AWSEBCloudwatchAlarmLow-1XFURG3PRQW54 2019-11-14 02:24:14 INFO Application available at dev-env-zkspacwmyg.cn-northwest-1.eb.amazonaws.com.cn. 2019-11-14 02:24:15 INFO Successfully launched environment: dev-env eb open   Make change and deploy  Make a change to index.html\neb deploy eb open   SSH to EB EC2 box  eb ssh   Clean up everything  eb terminate --all admin@~/ws/zaws-eb-p-blue$eb terminate --all The application \u0026quot;zaws-eb-p-blue\u0026quot; and all its resources will be deleted. This application currently has the following: Running environments: 1 Configuration templates: 0 Application versions: 2 To confirm, type the application name: zaws-eb-p-blue Removing application versions from s3. 2019-11-14 05:53:39 INFO deleteApplication is starting. 2019-11-14 05:53:40 INFO Invoking Environment Termination workflows. 2019-11-14 05:53:40 INFO The environment termination step is done. 2019-11-14 05:53:41 INFO The application has been deleted successfully.  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/ssh-tunnel-http-proxy-socks/",
        "title": "ssh tunnel \u0026 http proxy through socks",
        "section": "blog",
        "date" : "2019.10.15",
        "body": " ssh tunnel  cmd ssh -C2qTnN -D 11111 -i ~/.ssh/ssh-rsa.ppk id@remote  C: Requests compression of all data 2: Forces ssh to try protocol version 2 only q: Quiet mode T: Disable pseudo-tty allocation n: Redirects stdin from /dev/null (actually, prevents reading from stdin) N: Do not execute a remote command (doesn't open the shell)  curl through http proxy  Using tunnel on terminal such as curl http/https  admin@~$cat .httpproxy export http_proxy=socks5://127.0.0.1:11111 export https_proxy=$http_proxy  Chrome  Start Chrome with proxy chrome \u0026ndash;proxy-server=\u0026ldquo;socks5://127.0.0.1:11111\u0026rdquo; \u0026ndash;host-resolver-rules=\u0026ldquo;MAP * 0.0.0.0 , EXCLUDE localhost\u0026rdquo;  Firefox and Safari  Similar to Chrome  Enjoy "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/security-ssh-key-pair-generation/",
        "title": "Security - Generating ssh key pair",
        "section": "blog",
        "date" : "2019.10.07",
        "body": " Objective To access a remote server through ssh keys\nUsing ssh-keygen tool ssh-keygen -t rsa -N \u0026ldquo;\u0026rdquo; -b 2048 -C \u0026ldquo;blue-cloud-kp\u0026rdquo; -f ./blue-cloud.pub\nReference  Manage key pair  Conclusion The key pair could be used to access remote servers.\n"
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/ubuntu1804_by_canonical/",
        "title": "Ubuntu1804 by Canonical",
        "section": "blog",
        "date" : "2019.08.27",
        "body": " Package mgmt  dpkg  # dkpg does not install dependencies automatically # See if apache2 is installed dpkg -l | grep apache2 # List all files installed for ufw dpkg -L ufw # Which package installed a file dpkg -S /etc/host.conf # Install a local .deb file sudo dpkg -i zip_3.0-4_i386.deb # Uninstalling a package sudo dpkg -r zip   apt - Ubuntu\u0026rsquo;s Advanced Packaging Tool (APT)  # apt [install | remove | update | upgrade] [$pkg1 $pkg2 ..] # Update the Package Index: The APT package index is essentially a database of available packages from the repositories defined in the /etc/apt/sources.list file and in the /etc/apt/sources.list.d directory. To update the index: apt update # discover to which package a file belongs apt-file search docker # Or using dpkg to find package names dpkg -S stdio.h # More apt help # Most used commands: list - list packages based on package names, [installed | upgradable ..] search - search in package descriptions = apt-cache search show - show package details = apt-cache show install - install packages remove - remove packages autoremove - Remove automatically all unused packages update - update list of available packages upgrade - upgrade the system by installing/upgrading packages full-upgrade - upgrade the system by removing/installing/upgrading packages edit-sources - edit the source information file # Diff between apt and apt-get: https://askubuntu.com/questions/445384/what-is-the-difference-between-apt-and-apt-get # apt is higher level of apt-get which is low level, backend of apt, and backwards compatible. apt is better for end-users and doesn't require or contain some extra features in that are present in apt-get.  Kernel Crash Dump  sudo apt install linux-crashdump /etc/default/kdump-tools // USE_KDUMP=1 Remote dump: SSH=\u0026ldquo;ubuntu@kdump-netcrash\u0026rdquo; or NFS=\u0026ldquo;kdump-netcrash:/var/crash\u0026rdquo; in /etc/default/kdump-tools Verification  cat /proc/cmdline // crashkernel boot parameter should be represented in /proc/cmdline   Verify that the kernel has reserved the requested memory area for the kdump kernel  dmesg | grep -i crash kdump-config show   Testing the Crash Dump Mechanism  cat /proc/sys/kernel/sysrq // SysRQ should be 1, if not, sudo sysctl -w kernel.sysrq=1 echo c \u0026gt; /proc/sysrq-trigger // to trigger the dump ls /var/crash  Tools  Cloud-init Juju MaaS  Getting help  Ubuntu server guide Ubuntu desktop guide Linux Kernel in a Nutshell  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/wordpress-docker-compose/",
        "title": "Docker-compose for Wordpress",
        "section": "blog",
        "date" : "2019.08.26",
        "body": " Get theme bitpal.zip  Bitpal theme  docker-compose.yml for wordpress cat docker-compose.yml version: '3.3' services: db: image: mysql:5.7 volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: * MYSQL_DATABASE: * MYSQL_USER: * MYSQL_PASSWORD: * wordpress: depends_on: - db image: wordpress:latest volumes: - /ws/bitpal:/var/www/html/wp-content/themes/bitpal # BitPal theme install ports: - \u0026quot;10000:80\u0026quot; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: * WORDPRESS_DB_PASSWORD: * WORDPRESS_DB_NAME: * volumes: db_data: {}  docker-compose up "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/wordpress-performance-tuning/",
        "title": "Wordpress performance tuning",
        "section": "blog",
        "date" : "2019.08.26",
        "body": " Disable unused features in theme I\u0026rsquo;m using BitPal them so here is what I did:\nAppearance -\u0026gt; Customize -\u0026gt; BitPal Performance -\u0026gt; Disable unused features in Icon Packs, Custom Post Types, Shortcodes sections\nRemove/Deactivate unused pages \u0026amp; plugins  Deactivate used plugins  Install WP Rocket (license required) This will give us options to - File optimization: Minify \u0026amp; combine css, js files - Media: Lazy loading - Enable OPcache - CDN\nTools  Google page speed https://gtmetrix.com/ [Imagify plugin] [WP Rocket caching]  Reference  7 Best WordPress Caching Plugins for 2019 LiteSpeed Cache vs. WP Rocket Memcached: What Is It and How to Use It on Your WordPress Site? Site Cache vs Browser Cache vs Server Cache: What’s the Difference? WordPress 性能优化：为什么我的博客比你的快 优化WordPress性能的高级指南 深入浅出讲述提升 WordPress 性能的九大秘笈 浅谈我是如何做的 WordPress 站点性能优化  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/vue-dive/",
        "title": "Get started with Vue",
        "section": "blog",
        "date" : "2019.08.26",
        "body": " Installation  vue.js\n Vue Devtools\n @vue/cli tool npm install -g @vue/cli // installed under /usr/local/lib/node_modules/@vue\n  Create a new Vue project vue create vue-demo # vue -h for help # preset: default (babel, eslint) # package manager to use when installing dependencies: Yarn cd vue-demo yarn serve # Use \u0026quot;vue ui\u0026quot; to start GUI mgmt console. Very cool!  Basics  v-bind (shorthand is :) Dynamically bind one or more attributes, or a component prop to an expression. or  v-on (@) \n v-slot (#)\n  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/learning-resources/",
        "title": "Learning resources",
        "section": "blog",
        "date" : "2019.07.31",
        "body": " Objective Get good learning resources\nKeywords  learning, resource, course  Architecture Reference  Azure AWS Aliyun  Microsoft Azure  skylines-academy-llc courses Services comparison between Azure \u0026amp; AWS  UI  Vue\n Vue2 + Bootstrap4 + Material design Bootstrap + Vue  Flutter\n  Flutter get started\n"
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/azure-notes/",
        "title": "Microsoft Azure Notes",
        "section": "blog",
        "date" : "2019.07.29",
        "body": " Determine workload requirement  Identifying requirements: Use cases, goals, scopes; Assumptions: Are we gonna use cloud native tools or traditional ones? Use existing licenses? Critical Success Factors: Need to be scalable to meet xyz workload, utilizing existing operation team, no new talent required? Plan for growth Manage cost  Complaince and security requirement  Data protection in EU: GDPR Healthcare: HIPPA Government: FedRAMP  SLA - Service Level Agreement  MTTR: Mean Time To Recovery. Avg time to recover service from outage MTBF: Mean Time Between Failure. Avg time between outages RPO: Recovery Point Objective. Interval of time in which data could be lost during a recovery. E.g. 5 minute RPO means up to 5 minutes of data could be lost RTO: Recovery Time Objective. Time requirement for recovery to be completed in before there is business impact Composite SLA: SQL 99.95% x Web App 99.5% = SLA 99.94%  Domain services  Azure Active Directory: AAD, often the same as O365 directory service Active Directory Domain Services: ADDS, legacy service, with AD installed on windows VM Azure Active Directory Domain Services: Managed domain services  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/kafka-cluster/",
        "title": "Kafka cluster",
        "section": "blog",
        "date" : "2019.07.24",
        "body": " Objective Setup Kafka cluster on three nodes\nEnvironment  Servers  9.98.13.49 9.98.13.50 9.98.13.52\nTODO "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/using-self-signed-ssl-certificate-for-aws-beanstalk/",
        "title": "Using self-signed SSL certificate for AWS Elastic Beanstalk",
        "section": "blog",
        "date" : "2019.07.24",
        "body": " Objective There are cases we need run a quick PoC with HTTPS enabled in AWS Elastic Beanstalk. In such cases, one of an efficient way is to use a self-signed certificate. Please note you can use AWS Certificate Manager to generate certificate if it\u0026rsquo;s enabled in your region. I\u0026rsquo;ll demostrate how to generate and use a self-signed certificate in AWS CLI here in this blog.\nKeywords  SSL, HTTPS, x509, Beanstalk, AWS  Environment  macOS in local AWS console in remote  Generating a new self-signed certificate  Generate a private key with length 2048  openssl genrsa 2048 \u0026gt; privatekey.pem   Generate a certificate signing request - csr  openssl req -new -key privatekey.pem -out csr.pem Country Name (2 letter code) []:CT State or Province Name (full name) []:State Locality Name (eg, city) []:City Organization Name (eg, company) []:ON Organizational Unit Name (eg, section) []:OU Common Name (eg, fully qualified host name) []:mypoc.eb.amazonaws.com Email Address []: my@email.com   Self sign the certificate  openssl x509 -req -days 3650 -in csr.pem -signkey privatekey.pem -out server.crt   Generate Access key for AWS CLI  Go to AWS console Users to generate Access key\n Configure AWS CLI  I\u0026rsquo;d use AWS CLI to upload the certificate, so I installed AWS CLI tool on my laptop.\nHere is a Guide to install AWS CLI\nAfter the installation, configure it:\naws configure # Output like this: AWS Access Key ID [****************]: ****** AWS Secret Access Key [****************]: ****** Default region name [None]: ****** Default output format [None]: json  Upload the certificate into AWS  Upload  aws iam upload-server-certificate --server-certificate-name elastic-beanstalk-x509 --certificate-body file://server.crt --private-key file://privatekey.pem # Output like this: { \u0026quot;ServerCertificateMetadata\u0026quot;: { \u0026quot;Path\u0026quot;: \u0026quot;/\u0026quot;, \u0026quot;ServerCertificateName\u0026quot;: \u0026quot;****************\u0026quot;, \u0026quot;ServerCertificateId\u0026quot;: \u0026quot;****************\u0026quot;, \u0026quot;Arn\u0026quot;: \u0026quot;****************\u0026quot;, \u0026quot;UploadDate\u0026quot;: \u0026quot;2019-07-23T10:33:13Z\u0026quot;, \u0026quot;Expiration\u0026quot;: \u0026quot;2029-07-20T10:02:18Z\u0026quot; } }  Use the new self-signed certificate in AWS Elastic Beanstalk (EB)  Enable Load balancer of EB  If EB does not exist, feel free to create one with web server environment tier.\nGo to Elastic Beanstalk Application -\u0026gt; Environment -\u0026gt; Configuration -\u0026gt; Capacity -\u0026gt; Modify -\u0026gt; Environment type -\u0026gt; Load balanced -\u0026gt; Apply\n Add listener  Go to Elastic Beanstalk Application -\u0026gt; Environment -\u0026gt; Configuration -\u0026gt; Load balancer -\u0026gt; Modify -\u0026gt; Add listener -\u0026gt; Listener port: 443, Listener protocol: HTTPS, Instance port: 80, Instance protocol: HTTP -\u0026gt; Add -\u0026gt; Apply the configuration\nVerify  Get the app URL and change the protocol to https on browser. Accept or add exception because it\u0026rsquo;s a self-signed certificate for low level environment testing purpose. It should be secure now.  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/open-stack-dive/",
        "title": "Dive into Openstack",
        "section": "blog",
        "date" : "2019.07.22",
        "body": " Objective Dive into Openstack\nKeywords  KVM, Openstack, Virtualization, Nova, Glance  Environment  Ubuntu 16.04 on Virtualbox for macOS  KVM  Kernel-based Virtual Machine kvm.ko for CPU \u0026amp; RAM mgmt Linux kernel \u0026amp; Qemu for I/O virtualization e.g. Storage \u0026amp; Networking Libvirt for managing Hypervisor like KVM, VirtualBox, Xen; Openstack uses Libvirt at its bottom Libvirt componments: libvirtd as daemon, API, virsh as CLI Virt-manager: GUI tool  KVM management  egrep -o \u0026lsquo;(vmx|svm)\u0026rsquo; /proc/cpuinfo service libvirt-bin status virt-manager virsh list // list virtual machines sudo apt-get install qemu-kvm qemu-system libvirt-bin virt-manager bridge-utils vlan sudo apt-get install xinit gdm kubuntu-desktop  vCPU  Every virtual CPU is a thread of process qemu-kvm vCPU can be overcommit, but need to be tested for performance  Virtual memory  Virtual Addres -\u0026gt; Physical Address on VM -\u0026gt; Machine Address on bare metal vMem can be overcommit, but need to be tested for performance  Stoage virtualization  Virtualization through Storage pool \u0026amp; volume Default storage pool: /var/lib/libvirt/images/ A file is basically a volume  Network virtualization VM0 (vnet0), VM1 (vnet1) \u0026mdash; br0 (Linux bridge) \u0026mdash; eth0 (Physical)\n Create bridge br0 and mount physical eth0 on br0 auto lo iface lo inet loopback  auto eth0 iface eth0 inet manual\nauto br0 iface br0 inet dhcp bridge_stp off bridge_waitport 0 bridge_fd 0 bridge_ports eth0\n brctl show ps -ef|grep dnsmasq // DHCP service, allocated IP could be found in config file: /var/lib/libvirt/dnsmasq/default.leases virsh list -all virsh domiflist VM1 Linux bridge Working on TCP/IP 2nd layer, as a hub or switch, to be connected by devices in the network virbr0 A default bridge created by KVM, to provide NAT services for vnet devices connected to the bridge\n VLAN Virtual Local Area Network\n Work on layer 2, meaning arp can not cross the border of LAN, IP on 3rd layer could be communicated using a router Switch with VLAN feature is required to implement VLAN. It can provide multiple LANs through its ports Two modes of port configuration: Access and Trunk   Tools  vmdiff // to compare files\n   "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/mongodb-sharding/",
        "title": "MongoDB sharding",
        "section": "blog",
        "date" : "2019.07.18",
        "body": " Objective Setup MongoDB sharding on three nodes\nEnvironment  Servers  9.98.13.49 9.98.13.50 9.98.13.52\nTODO "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/a-quick-taste-of-go-channel-performance/",
        "title": "Goroutine \u0026 bufferred channel's quick performance taste: TPS from 28k to 16m",
        "section": "blog",
        "date" : "2019.07.13",
        "body": " Objective To get TPS (Transaction Per Second) as high as possible by using goroutine \u0026amp; bufferred channel (CSP pattern)\nEnvironment  2.3 GHz Intel Core i5; 8 GB 2133 MHz LPDDR3 macOS Mojave 10.14.4 Go 1.12.6  Setup Go If you are new to Golang, for Go\u0026rsquo;s setup, please refer to my blog: Go - Build a web API\nCreate a Go project mkdir -p ~/ws/golang/src/blue/demo cd ~/ws/golang/src/blue/demo vim demo.go  package main import ( \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) var load = 100000 // CSP Communicating Sequential Processes func consumer(data chan int, done chan bool) { for i := range data { fmt.Println(\u0026quot;Consuming:\u0026quot;, i) } done \u0026lt;- true } func producer(data chan int) { for i := 0; i \u0026lt; load; i++ { fmt.Println(\u0026quot;Producing:\u0026quot;, i) data \u0026lt;- i } close(data) } func demoChannelRoutine() { start := time.Now() data := make(chan int) done := make(chan bool, 1) go consumer(data, done) go producer(data) \u0026lt;-done elapsed := time.Since(start).Seconds() fmt.Printf(\u0026quot;Elapsed: %.3fs\\n\u0026quot;, elapsed) tps := float64(load) / elapsed fmt.Printf(\u0026quot;TPS: %.0f\\n\u0026quot;, tps) }  1st run, TPS 28k go build demo.go ./demo # Output ... Producing: 99998 Producing: 99999 Consuming: 99998 Consuming: 99999 Elapsed: 3.506s Transaction Per Second: 28521 Cleaning up..  Removing printing I/O and 2nd run, TPS boosts from 28k to 3m // Only changed part listed here var load = 100000 func consumer(data chan int, done chan bool) { for i := range data { //fmt.Println(\u0026quot;Consuming:\u0026quot;, i) if i \u0026lt; 0 { } } done \u0026lt;- true } func producer(data chan int) { for i := 0; i \u0026lt; load; i++ { //fmt.Println(\u0026quot;Producing:\u0026quot;, i) data \u0026lt;- i } close(data) }  go build demo.go ./demo # Output ... Elapsed: 0.027s Transaction Per Second: 3738271 Cleaning up..  Bufferred channel \u0026amp; 3rd run, TPS boosts from 3m to 16m // Only changed part listed here var load = 100000000 var chBuf = 10000 ... data := make(chan int, chBuf)  go build demo.go ./demo # Output Elapsed: 6.047s Transaction Per Second: 16537191 Cleaning up..  Conclusion This is a quick test of goroutine + bufferred channel. From introducing heavy I/O (printing) to only RAM I/O. I could boost TPS from 28k to 3m. By introducing bufferred channel, I boosted TPS from 3m to 16m.\n"
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/automation-ansible/",
        "title": "Automation with Ansible",
        "section": "blog",
        "date" : "2019.07.05",
        "body": " Playbook Plays -\u0026gt; Tasks -\u0026gt; Modules -\u0026gt; Handlers\nModules more than 450 modules provided by Ansible common modules: yum, ping\nHow to  yum install ansible Ad-Hoc: ansible $inventory -m ping Playbook: ansible-playbook mybook.yml Ansible Tower: Options, Dry-run, -C mode ansible-doc ansible-galaxy ansible-config ansible-inventory ansible-pull ansible-vault ansible-console  Configuration /etc/ansible/ansible.cfg /etc/ansible/hosts /etc/ansible/roles/\nInventory  Host 192.168.0.2 www.example.com www[01:50].example.com\n Host var www.example.com k1=v1 k2=v2\n Group [group name] www.example.com k1=v1 k2=v2 192.168.0.2 k1=v1 k2=v2\n Group var [GroupName:vars] k1=v1 k2=v2\n  Get hands dirty  ansible $host-or-group-name -m copy -a \u0026ldquo;content=\u0026lsquo;hello\u0026rsquo; dest=/root/hello.txt\u0026rdquo;  Reference  One hour Ansible CN version  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/bruce-cloud-native-map/",
        "title": "Bruce's Cloud Native Skillset Map",
        "section": "blog",
        "date" : "2019.07.05",
        "body": ""
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/ms-spring-cloud/",
        "title": "Microservices with Spring Cloud",
        "section": "blog",
        "date" : "2019.07.05",
        "body": " Introduction  Spring Cloud provides tools for developers to quickly build some of the common patterns in distributed systems (e.g. configuration management, service discovery, circuit breakers, intelligent routing, micro-proxy, control bus, one-time tokens, global locks, leadership election, distributed sessions, cluster state). Coordination of distributed systems leads to boiler plate patterns, and using Spring Cloud developers can quickly stand up services and applications that implement those patterns. They will work well in any distributed environment, including the developer’s own laptop, bare metal data centres, and managed platforms such as Cloud Foundry.\n Features  Spring Cloud focuses on providing good out of box experience for typical use cases and extensibility mechanism to cover others. Distributed/versioned configuration Service registration and discovery Routing Service-to-service calls Load balancing Circuit Breakers Global locks Leadership election and cluster state Distributed messaging  Spring Cloud Kubernetes  Run Spring Cloud Apps on Kubernetes  Spring Cloud Kubernetes\n"
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/jvm-tuning/",
        "title": "JVM tuning",
        "section": "blog",
        "date" : "2019.07.04",
        "body": " Tags jvm tuning jstat jhat jmap gc  Env  Spring Cloud Greenwich Spring Boot 2.1.5 Java HotSpot\u0026trade; 64-Bit Server VM (build 25.181-b13, mixed mode) STS (Spring Tool Suite) 4.1.1 MackBook Pro Mojave  Objective  Minimize Full GC, down to 0 if possible  Prerequisites  Build a jar  mvn -B -DskipTests clean package  Baseline - default jvm settings  Run  java -jar discovery-center-0.0.1-SNAPSHOT.jar   jstat -gc  S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 7168.0 8192.0 7160.1 0.0 494080.0 332080.5 82944.0 15609.6 46760.0 4 4845.5 6312.0 5953.5 12 0.063 2 0.118 0.181   Timing   5.814 = 2019-06-25 22:32:57.974 - 2019-06-25 22:33:03.788  1st try: still 1 FGC  Run  java -jar -Xms768m -Xmx768m -Xmn700m -XX:SurvivorRatio=10 -XX:+PrintGCDetails -XX:MetaspaceSize=50M discovery-center-0.0.1-SNAPSHOT.jar   jstat  S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 59392.0 59392.0 0.0 0.0 598016.0 264071.9 69632.0 23958.9 51200.0 48840.8 7040.0 6531.4 4 0.122 1 0.192 0.313   Timing  5.542 = 2019-06-25 22:46:48.423 - 2019-06-25 22:46:53.965  2nd try: 0 Full GC  Run  java -jar -Xms768m -Xmx768m -Xmn700m -XX:SurvivorRatio=10 -XX:+PrintGCDetails -XX:MetaspaceSize=80M discovery-center-0.0.1-SNAPSHOT.jar   jstat  S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 59392.0 59392.0 0.0 24209.6 598016.0 204594.4 69632.0 104.0 51584.0 49021.5 7040.0 6555.6 3 0.127 0 0.000 0.127   Timing  5.166 = 2019-06-25 22:57:28.061 - 2019-06-25 22:57:33.227  Heap dump  cmds  jmap -dump:format=b,file=discovery-center.dump $java-pid jhat -port 8888 discovery-center.dump\n GUI Tools  Eclipse MAT, jconsole, jvisualvm, visualvm\n"
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/go-build-a-web-api/",
        "title": "Go - Build a web API",
        "section": "blog",
        "date" : "2019.07.04",
        "body": " Objective Build a web API by using Go language on Linux\nSetup Go  Download  wget https://dl.google.com/go/go1.12.4.linux-amd64.tar.gz tar -C /usr/local -xzf ./go1.12.4.linux-amd64.tar.gz\n Configure PATH  Add Go to PATH in ~/.bash_profile\nexport PATH=$PATH:/usr/local/go/bin   Source  . ~/.bash_profile   Reference  Create a Go project mkdir -p /opt/ws/go/src/blue/http cd /opt/ws/go/src/blue/http vim BlueHTTPServer.go  package main; import ( \u0026quot;net/http\u0026quot; ) func say(res http.ResponseWriter, req *http.Request) { res.Write([]byte(\u0026quot;Hey Bruce!\u0026quot;)); } func main(){ http.HandleFunc(\u0026quot;/say\u0026quot;, say); http.Handle(\u0026quot;/say2\u0026quot;, http.HandlerFunc(say)); http.ListenAndServe(\u0026quot;:10001\u0026quot;, nil); select{}; }  Build and run go build BlueHTTPServer.go ./BlueHTTPServer  Test curl http://localhost:10001/say curl http://localhost:10001/say2 # I can see output like this: Hey Bruce!  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/ms-pattern-theory/",
        "title": "Microservices principles",
        "section": "blog",
        "date" : "2019.07.04",
        "body": " DDD  Domain-driven design (DDD) is an approach to software development for complex needs by connecting the implementation to an evolving model. Reference: https://airbrake.io/blog/software-design/domain-driven-design\n CAP  The CAP Theorem is a fundamental theorem in distributed systems that states any distributed system can have at most two of the following three properties. Consistency. Availability. Partition tolerance.\n ACID \u0026amp; BASE  ACID\n Atomic: Everything in a transaction succeeds or the entire transaction is rolled back. Consistent: A transaction cannot leave the database in an inconsistent state. Isolated: Transactions cannot interfere with each other. Durable: Completed transactions persist, even when servers restart etc.  BASE\n Basic Availability Soft-state Eventual consistency   Paxos Raft AKF Scale Cube scale-cube\nSaga Saga pattern\nBFF Backend For Frontend\nReference  Patterns for microservices  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/coding-nodejs-async-await/",
        "title": "Promise, async and await",
        "section": "blog",
        "date" : "2019.07.04",
        "body": " Promise, async and await async function f() { try { let response = await fetch('/no-user-here'); let user = await response.json(); } catch(err) { // catches errors both in fetch and response.json alert(err); } } f(); // reference: https://javascript.info/async-await // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function  A full html for demo and testing \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Demo of async await promise\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Demo of async await promise \u0026lt;script lang=\u0026quot;javascript\u0026quot;\u0026gt; /* ## Promise The Promise object represents the eventual completion (or failure) of an asynchronous operation, and its resulting value. A Promise is a proxy for a value not necessarily known when the promise is created. It allows you to associate handlers with an asynchronous action's eventual success value or failure reason. This lets asynchronous methods return values like synchronous methods: instead of immediately returning the final value, the asynchronous method returns a promise to supply the value at some point in the future. A Promise is in one of these states: pending: initial state, neither fulfilled nor rejected. fulfilled: meaning that the operation completed successfully. rejected: meaning that the operation failed. A pending promise can either be fulfilled with a value, or rejected with a reason (error). When either of these options happens, the associated handlers queued up by a promise's then method are called. (If the promise has already been fulfilled or rejected when a corresponding handler is attached, the handler will be called, so there is no race condition between an asynchronous operation completing and its handlers being attached.) It has then, catch and finally methods. My understanding: Promise resolved the problem of callback hell. It allows you to associate/attach handlers instead of treat them as function parameters. loadScript(src, callback1, callback2, callback3); loadSomething(src).then(callback1) .then(callback2) .then(callback3); ## async, await (a -\u0026gt; asynchronous) async keyword, which you put in front of a function declaration to turn it into an async function. An async function is a function which knows how to expect the possibility of the await keyword being used to invoke asynchronous code. The real advantage of async functions becomes apparent when you combine it with the await keyword. This can be put in front of any async promise-based function to pause your code on that line until the promise fulfills, then return the resulting value. In the meantime, other code that may be waiting for a chance to execute gets to do so. You can use await when calling any function that returns a Promise, including web API functions. async myFetch(url){ let res = await fetch(url); } The return value of async function is a Promise, you can call then on it. My understanding: async \u0026amp; await make writing async code like sync code, easier to read \u0026amp; maintain. ## Ref [Async_await](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await) [js info](https://javascript.info/async) */ // async await demo async function fun() { let res = null; // await can be put in front of any async promise-based function to pause your code on that // line until the promise fulfills, then return the resulting value. res = await new Promise((resolve, reject)=\u0026gt;{ //setTimeout(() =\u0026gt;{console.log('in promise');}, 1000); // To simulate a delay setTimeout(() =\u0026gt;{resolve('Resolved'); console.log('in promise');}, 1000); }); console.log('res: ' + res); return res; } // promise demo let myPromise = new Promise((resolve, reject)=\u0026gt;{ // use setTimeout to simulate some async time consuming work setTimeout(() =\u0026gt; resolve(\u0026quot;Done myPromise!\u0026quot;),3000); }); console.log(\u0026quot;start..\u0026quot;); myPromise.then(data =\u0026gt; {console.log(data)}); console.log(fun()); console.log(\u0026quot;end.\u0026quot;); /* Output may look like: start.. Promise {\u0026lt;pending\u0026gt;} end. in promise res: Resolved Done myPromise! */ \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/coding-python/",
        "title": "Coding with Python",
        "section": "blog",
        "date" : "2019.07.04",
        "body": " yield #!/usr/bin/env python # Author Bruce 12/14/17 import sys def greppattern(pattern, fullfilename): with open(fullfilename) as handle: for line in handle: if pattern in line: yield line.rstrip(\u0026quot;\\n\u0026quot;) if __name__ == \u0026quot;__main__\u0026quot;: # python blueutils.py \u0026quot;30 15\u0026quot; dbcontrace.log ''' usage: python blueutils.py \u0026quot;17-12\u0026quot; dbcontrace.log ''' pattern, fullfilename = sys.argv[1], sys.argv[2] for line in greppattern(pattern, fullfilename): print(line)  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/docker-cmds/",
        "title": "Docker Commands",
        "section": "blog",
        "date" : "2019.07.04",
        "body": " Get help  Get help\ndocker -h\n Get help for a command\ndocker image prune \u0026ndash;help\n  Container  Show all containers, including both running and stopped\ndocker ps -a\n Get container logs\ndocker logs $container\n Attach std in/out/error to a running container\ndocker attach $container\n Run a command in a running container interactively\ndocker exec -it $container /bin/sh\n Show detail of a container\ndocker inspect $container\n Stats\ndocker stats $container\n Start/stop a container\ndocker start / stop $container\n Remove a container\ndocker rm $container\n Check container network from outside of the container (If container doesn\u0026rsquo;t have networking tools installed)\n docker inspect -f \u0026lsquo;{{.State.Pid}}\u0026rsquo; serene_curran nsenter -t pId -n tcpdump -i any tcp port 8883 -w ds.dump nsenter -t pId -n lsof -i :8883 nsenter -t pId -n netstat -neoap  Docker restart policy\n docker run -itd \u0026ndash;restart always -p 9090:9090 antivirus others: unless-stopped, on-failure (based on exit code), no Max retries to restart if on failure e.g. \u0026ndash;restart on-failure:5   Image  basic actions\ndocker image ls docker image history $image docker rmi $image\n Remove all unused images, not just dangling ones\ndocker image prune -a docker rmi -f $(docker images \u0026ndash;filter \u0026ldquo;dangling=true\u0026rdquo; -q \u0026ndash;no-trunc) // Be very careful!\n  Networking  List docker networks\ndocker network ls\n  Run Nginx in Docker  docker run \u0026ndash;name some-nginx -v /some/content:/usr/share/nginx/html:ro -d nginx docker run \u0026ndash;name my-custom-nginx-container -v /host/path/nginx.conf:/etc/nginx/nginx.conf:ro -d nginx docker cp tmp-nginx-container:/etc/nginx/nginx.conf /host/path/nginx.conf  Run PHP in Docker  docker run -d -p 8080:80 \u0026ndash;name my-apache-php-app -v \u0026ldquo;$PWD\u0026rdquo;:/var/www/html php:7.2-apache  Cleanup  Docker - How to cleanup (unused) resources  Once in a while, you may need to cleanup resources (containers, volumes, images, networks) ... delete volumes // see: https://github.com/chadoe/docker-cleanup-volumes $ docker volume rm $(docker volume ls -qf dangling=true) $ docker volume ls -qf dangling=true | xargs -r docker volume rm delete networks $ docker network ls $ docker network ls | grep \u0026quot;bridge\u0026quot; $ docker network rm $(docker network ls | grep \u0026quot;bridge\u0026quot; | awk '/ / { print $1 }') remove docker images // see: http://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images $ docker images $ docker rmi $(docker images --filter \u0026quot;dangling=true\u0026quot; -q --no-trunc) $ docker images | grep \u0026quot;none\u0026quot; $ docker rmi $(docker images | grep \u0026quot;none\u0026quot; | awk '/ / { print $3 }') remove docker containers // see: http://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images $ docker ps $ docker ps -a $ docker rm $(docker ps -a -q) $ docker rm $(docker ps -qa --no-trunc --filter \u0026quot;status=exited\u0026quot;) Resize disk space for docker vm $ docker-machine create --driver virtualbox --virtualbox-disk-size \u0026quot;40000\u0026quot; default  Ref How To Remove Docker Containers, Images, Volumes, and Networks\n"
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/kubernetes-cmds/",
        "title": "Kubernetes Commands",
        "section": "blog",
        "date" : "2019.07.04",
        "body": " Create/run  kubectl run busybox \u0026ndash;rm -it \u0026ndash;image=busybox /bin/sh kubectl run nginx \u0026ndash;image=nginx \u0026ndash;replicas=2 kubectl run nginx \u0026ndash;image=nginx \u0026ndash;dry-run kubectl create -f a-file.yml kubectl create deployment kubernetes-bootcamp \u0026ndash;image=gcr.io/google-samples/kubernetes-bootcamp:v1  Get info  kubectl -h or \u0026ndash;help kubectl $command \u0026ndash;help kubectl cluster-info kubectl get nodes kubectl get pods -o wide \u0026ndash;all-namespaces kubectl get po -o yaml kubectl get pod -l app=ratings -o jsonpath=\u0026lsquo;{.items[0].metadata.name}\u0026rsquo; kubectl get pods -o go-template \u0026ndash;template \u0026lsquo;{{range.items}}{{.metadata.status}}{{\u0026rdquo;\\n\u0026rdquo;}}{{end}}\u0026rsquo; kubectl get deployments kubectl get services kubectl get namespace kubectl get pv kubectl get statefulsets kubectl describe resName kubectl explain resName kubectl proxy and curl http://localhost:8001/version  Trouble shooting  kubectl logs -p $pod -c $container kubectl logs \u0026ndash;since=1h nginx kubectl exec -it myPodName -c containerNameInMyPod /bin/sh  Apply changes  kubectl apply -f a-file.yml kubectl delete -f a-file.yml kubectl scale \u0026ndash;replicas=3 deployment/nginx  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/linux-shells/",
        "title": "Linux Shells",
        "section": "blog",
        "date" : "2019.07.03",
        "body": " for for i in {1..10}; do echo $i;done  if # admin@~/ws/shell$cat weight-check.sh #!/bin/bash # Author: Bruce #if [ ! $# -eq 2 ]; then if [ $# -lt 2 ]; then echo \u0026quot;Not enough parameters. Usage: $0 weight-in-kilos lengh-in-centimeters\u0026quot; exit elif [ $# -gt 2 ]; then echo \u0026quot;Too many parameters. Usage: $0 weight-in-kilos lengh-in-centimeters\u0026quot; exit else # \u0026quot;\u0026quot; -\u0026gt; true; \u0026quot; \u0026quot; -\u0026gt; false if [ -z \u0026quot;$1\u0026quot; ]; then echo \u0026quot;1st parameter empty\u0026quot; exit fi if [ -n \u0026quot;$2\u0026quot; ]; then echo \u0026quot;2nd parameter not empty\u0026quot; fi echo -n \u0026quot;You entered: \u0026quot; for p in \u0026quot;$1\u0026quot; \u0026quot;$2\u0026quot;;do echo -n \u0026quot;$p \u0026quot; done echo \u0026quot;\u0026quot; fi if [ -f lock ]; then echo \u0026quot;Already run\u0026quot; fi # Adding lock if not yet echo \u0026quot;lock\u0026quot; \u0026gt; lock weight=\u0026quot;$1\u0026quot; height=\u0026quot;$2\u0026quot; ideal=$[height - 110] if [ $weight -gt $ideal ]; then echo \u0026quot;Less yummy food please\u0026quot; elif [ $weight -eq $ideal ]; then echo \u0026quot;Goodness, you are perfect!\u0026quot; else echo \u0026quot;More food please\u0026quot; fi rm -f lock  TODO "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/linux-cool-cmd/",
        "title": "Linux Cool Commands",
        "section": "blog",
        "date" : "2019.07.03",
        "body": " Editing  vim  # Remove trailing spaces :%s/\\s\\+$//   sed -r \u0026rsquo;s/\\s+//g\u0026rsquo; afile sort afile|uniq sed  # sed [options] 'row-range+action' file # Actions: i, a, d, c, p, s # +g, +i # In place replacement, original copy with .bk suffix is created sed -i.bk 's/Z/1/g' afile # Remove lines from 3 to end sed '3,$d' # Print line 1 and line 2 only sed -n '1,2p' afile # Print lines match pattern sed -n '/A/p' afile   awk  # awk 'pattern{action}' filenames last -n 5 | awk '{print $1}' cat /etc/passwd |awk -F ':' 'BEGIN {print \u0026quot;name,shell\u0026quot;} {print $1\u0026quot;,\u0026quot;$7} END {print \u0026quot;blue,/bin/nosh\u0026quot;}' awk -F: '/^root/{print $7}' /etc/passwd   cut  # Print 1st field, each field separated by : cut -d: -f 1 /etc/passwd  Searching  find  find /etc -name passwd find . -name \u0026quot;*.txt\u0026quot; -exec echo {} \\; -exec grep banana {} \\; find ./ -type d |xargs ls -l # -I replace_str; -0 take cares of file names with blank space find . -name \u0026quot;*.bak\u0026quot; -print0 | xargs -0 -I {} mv {} ~/old.files # {} could be customized as whatever, like file in the example find /path/to/dir -iname \u0026quot;*.c\u0026quot; -print0 | xargs -0 -I file mv file ~/old.src   ls  # List one column ls -1  Logging  dmesg // kernel message, equals to journalctl -k journalctl -a /var/log  Resources  ps -ef|grep java top vmstat sar  Networking  netstat -anp|grep 80 lsof -i :80 tcpdump   Storage  lsblk fdisk -l iotop  Kernel Performance  time ls watch -n 2 free  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/how-i-build-this-web-site/",
        "title": "How I Built This Web Site within an hour",
        "section": "blog",
        "date" : "2019.07.03",
        "body": " Objective Build a web site like this within an hour.\nLocal env.  macOS Mojave Hugo v0.55.6 for Mac git version 2.20.1 (client)  Prepare local env.  Install Hugo\nbrew install hugo\n Install git client\nbrew install git\n  On Github  Log on Github Create a public repository named bruce-lu.github.io\nWhere bruce-lu is my Github account name. I create a new repository bruce-lu.github.io on Github.\n  On local env.  Create workspace\nmkdir ~/ws \u0026amp;\u0026amp; cd ~/ws\n Clone the new repository\ngit clone https://github.com/bruce-lu/bruce-lu.github.io.git\n Create a Hugo site and get pulp theme\ncd bruce-lu.github.io\nmkdir site \u0026amp;\u0026amp; cd site \u0026amp;\u0026amp; git submodule add https://github.com/koirand/pulp.git themes/pulp\ncp -r themes/pulp/exampleSite/* ./\n Run the web site locally\nhugo server -D\n The first test\nhttp://localhost:1313\n Make changes in config.toml\nbaseurl = \u0026ldquo;https://bruce-lu.github.io/\u0026quot; title = \u0026ldquo;Bruce Lu\u0026rsquo;s pages\u0026rdquo; theme = \u0026ldquo;pulp\u0026rdquo;\n Add some content\nhugo new blog/first.md vim content/blog/first.md change draft: from true to false\n The second test\nhttp://localhost:1313/blog\n  Publish to Github  Generate static web pages\nhugo\nThere would be a public folder generated.\n copy files in public folder to root folder cp -r public/* ../\nThe folder structure looks like this:\n├── 404.html ├── blog │ ├── emoji-support │ │ └── index.html │ ├── index.html │ ├── index.json │ ├── markdown-syntax │ │ └── index.html │ ├── math-typesetting │ │ └── index.html │ ├── placeholder-text │ │ └── index.html │ ├── rich-content.md.bk │ └── second │ └── index.html ├── bundle.min.87ff415004641d66f3d4fb9cbf76ce073ce8a10dd5b67afca5054b00be4ebc9a.js ├── css │ └── custom.css ├── img │ ├── avatar-border.svg │ ├── avatar.jpg │ ├── clear.png │ ├── favicon.ico │ └── search.png ├── index.html ├── index.xml ├── js │ └── custom.js ├── resources │ └── _gen │ ├── assets │ └── images ├── series │ ├── index.html │ └── index.xml ├── site │ ├── config.toml │ ├── content │ │ └── blog │ ├── public │ │ ├── 404.html │ │ ├── blog │ │ ├── bundle.min.87ff415004641d66f3d4fb9cbf76ce073ce8a10dd5b67afca5054b00be4ebc9a.js │ │ ├── css │ │ ├── img │ │ ├── index.html │ │ ├── index.xml │ │ ├── js │ │ ├── series │ │ ├── sitemap.xml │ │ ├── style.min.60c59e75c5046f0eded1491ec81bdadd4a68c3cb5d8aa97aeaa80d79260917d3.css │ │ └── style.min.a6cab246517742ad1189b209575fc61556550e663cdfe02a0aab0632b39e978b.css │ ├── resources │ │ └── _gen │ ├── series │ │ ├── index.html │ │ └── index.xml │ ├── static │ │ ├── css │ │ ├── img │ │ └── js │ └── themes │ └── pulp ├── sitemap.xml └── style.min.a6cab246517742ad1189b209575fc61556550e663cdfe02a0aab0632b39e978b.css   Push code  cd ~/ws/bruce-lu.github.io git add . git commit -m \u0026ldquo;Initial publish\u0026rdquo; git push\n Validate  Wait for like 1 or 2 minutes, open https://bruce-lu.github.io/\nFeel free to add more blogs and enjoy ;-)   Analysis  Add Google Analysis support  Edit bruce-lu.github.io/site/config.toml\n# Put your tracking id here and rebuild \u0026amp; publish the site. googleAnalytics = \u0026quot;MyGoogleAnalyticsTrackingID\u0026quot; # Visit Google Analytics console:\thttps://analytics.google.com/ for real time metrics  Reference  Hugo quick-start guide Getting Started with GitHub Pages pulp theme guide  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/how-to-start-a-speech/",
        "title": "Note of How to start a speech",
        "section": "blog",
        "date" : "2019.05.24",
        "body": " Thanks to  How to start a speech  Keywords  speech  The 3rd way: With a question that maters to the audience The 2nd way: A fact that shockes (change your thinking) There is more people that is alive today than ever died Every 2 minutes, the energy reaching the earch from the sun is equivalent to the whole annual usage of humanity\nThe best way: Tell stories from own life, talk about people behind the story  The same way we start a story to a child: Once upon a time. When the story coming, people are listening  Conclusion  Start with A Question\n Start with curious \u0026amp; bizarre fact\n Start with a relevant story\n  "
    }
,
    {
        "ref": "https://bruce-lu.github.io/blog/markdown-syntax/",
        "title": "Markdown Syntax Guide",
        "section": "blog",
        "date" : "2019.03.11",
        "body": "This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution  Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\n Blockquote with attribution  Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\n Tables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23    Inline Markdown within tables    Inline\u0026nbsp;\u0026nbsp;\u0026nbsp; Markdown\u0026nbsp;\u0026nbsp;\u0026nbsp; In\u0026nbsp;\u0026nbsp;\u0026nbsp; Table     italics bold strikethrough\u0026nbsp;\u0026nbsp;\u0026nbsp; code    Code Blocks Code block with backticks html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Code block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List  First item Second item Third item  Unordered List  List item Another item And another item  Nested list  Item First Sub-item Second Sub-item  Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015. [return]  "
    }
]
